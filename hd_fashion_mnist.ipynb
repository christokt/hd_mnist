{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2ae092d1f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Set torch seed\n",
    "torch.manual_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Hyperparameters\n",
    "HD_DIMENSION = 40000\n",
    "NUM_CLASSES = 10\n",
    "THRESHOLD = 0.0\n",
    "BATCH_SIZE = 8\n",
    "IMG_LEN = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "hd_device = torch.device('cpu')\n",
    "# device = torch.device('mps')\n",
    "\n",
    "print('Using device:', device)\n",
    "\n",
    "# Load MNIST Data\n",
    "transform = transforms.ToTensor()\n",
    "train_data = torchvision.datasets.FashionMNIST(root='data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(root='data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate HD vectors\n",
    "def generate_hd_vectors(images, proj):\n",
    "\n",
    "    # Adjust proj to sit between -1 and 1\n",
    "    proj = (proj * 2) - 1\n",
    "\n",
    "    # Send images to device\n",
    "    images = images.to(hd_device)\n",
    "\n",
    "    # Generate hypervectors and create binary vector\n",
    "    hd_vectors = torch.sign(images @ proj.T)\n",
    "    \n",
    "    return hd_vectors.to(hd_device)\n",
    "\n",
    "# Classify hd vectors using cosine similarity\n",
    "def classify_hd_vectors(hd_vectors, hd_memory):\n",
    "    distances = torch.cdist(hd_vectors, hd_memory, p=2)\n",
    "    \n",
    "    # Find the index of the minimum distance\n",
    "    min_distances, min_indices = torch.min(distances, dim=1)\n",
    "    return min_indices.to(hd_device)\n",
    "\n",
    "def create_hd_memory(hd_vectors, labels, HD_DIMENSION):\n",
    "    # Initialize HD Memory for classes\n",
    "    hd_memory = torch.zeros((NUM_CLASSES, HD_DIMENSION), device=hd_device)\n",
    "\n",
    "    # Create HD Memory\n",
    "    for i, vec in enumerate(hd_vectors):\n",
    "        hd_memory[train_data.targets[i]] += vec\n",
    "\n",
    "    return torch.sign(hd_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create projection matrix\n",
    "proj = torch.rand((HD_DIMENSION, IMG_LEN), device=hd_device, dtype=torch.float32)\n",
    "\n",
    "# Create hyper vectors\n",
    "hd_vectors = generate_hd_vectors(train_data.data.view(train_data.data.shape[0], -1) / 255, proj)\n",
    "\n",
    "hd_memory = create_hd_memory(hd_vectors, train_data.targets, HD_DIMENSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to binary for faster computation\n",
    "def to_binary(hd_vectors, hd_memory):\n",
    "    hd_vectors = (hd_vectors == 1).to(torch.float32)\n",
    "    hd_memory = (hd_memory == 1).to(torch.float32)\n",
    "    return hd_vectors, hd_memory\n",
    "\n",
    "hd_vectors, hd_memory = to_binary(hd_vectors, hd_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing training data\n",
    "classifications = classify_hd_vectors(hd_vectors, hd_memory)\n",
    "\n",
    "correct = torch.sum(classifications == train_data.targets.to(hd_device))\n",
    "total = len(train_data.targets)\n",
    "print(f\"Accuracy on training data: {correct / total * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on test data\n",
    "hd_vectors_test = generate_hd_vectors(test_data.data.view(test_data.data.shape[0], -1) / 255, proj)\n",
    "hd_vectors_test = (hd_vectors_test == 1).to(torch.float32)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "classifications = classify_hd_vectors(hd_vectors_test, hd_memory)\n",
    "\n",
    "for i, classification in enumerate(classifications):\n",
    "    if classification == test_data.targets[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "print(f\"Accuracy on test data: {correct / total * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy when applying random noise to images\n",
    "noise_level = 0.85\n",
    "\n",
    "noise_matrix = torch.randn((test_data.data.shape[0], IMG_LEN), device=hd_device) * noise_level\n",
    "\n",
    "# Plot noise matrix\n",
    "noisy_test_data = (test_data.data.view(test_data.data.shape[0], -1) / 255).to(hd_device) + noise_matrix\n",
    "\n",
    "plt.imshow(noisy_test_data[0].view(28, 28).cpu(), cmap='gray')\n",
    "\n",
    "hd_vectors_noise = generate_hd_vectors(noisy_test_data, proj)\n",
    "hd_vectors_noise = (hd_vectors_noise == 1).to(torch.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test noisy test data\n",
    "classifications = classify_hd_vectors(hd_vectors_noise, hd_memory)\n",
    "\n",
    "correct = torch.sum(classifications == test_data.targets.to(hd_device))\n",
    "total = len(test_data.targets)\n",
    "print(f\"Accuracy on test data with noise: {correct / total * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and training an MLP for MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(IMG_LEN, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, IMG_LEN)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# Create neural network\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train neural network\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (BATCH_SIZE, 28*28)\n",
    "        images = images.view(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss and accuracy after each epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Accuracy\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop to evaluate the model using test_loader\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train a hybrid CNN feature extractor with hyperdimensional based feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 2.2179520716101435, Accuracy: 71.76333333333334%\n",
      "Epoch 2/10, Average Loss: 2.217902425992287, Accuracy: 71.755%\n",
      "Epoch 3/10, Average Loss: 2.2179659948510637, Accuracy: 71.69166666666666%\n",
      "Epoch 4/10, Average Loss: 2.217938081692841, Accuracy: 71.715%\n",
      "Epoch 5/10, Average Loss: 2.217919848733029, Accuracy: 71.79333333333334%\n",
      "Epoch 6/10, Average Loss: 2.2179317110675876, Accuracy: 71.79333333333334%\n",
      "Epoch 7/10, Average Loss: 2.2178828473818504, Accuracy: 71.74666666666667%\n",
      "Epoch 8/10, Average Loss: 2.2179099361775285, Accuracy: 71.70833333333333%\n",
      "Epoch 9/10, Average Loss: 2.2179823426877037, Accuracy: 71.835%\n",
      "Epoch 10/10, Average Loss: 2.2179029917312882, Accuracy: 71.62%\n"
     ]
    }
   ],
   "source": [
    "from models import HDCNN\n",
    "\n",
    "# Create HD-CNN\n",
    "hd_cnn = HDCNN(HD_DIMENSION).to(device)\n",
    "\n",
    "# Initialize class prototype dictionary for HD-CNN\n",
    "class_prototypes = {}\n",
    "for i in range(NUM_CLASSES):\n",
    "    class_prototypes[i] = torch.zeros(HD_DIMENSION, device=device)\n",
    "\n",
    "\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, hd_cnn.parameters()), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # Send data to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        hd_vectors = hd_cnn(inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Incrementally update class prototypes\n",
    "            for hd_vector, label in zip(hd_vectors, labels):\n",
    "                # Binarize hd_vector\n",
    "                hd_vector = torch.sign(hd_vector)\n",
    "\n",
    "                # Update class prototype by summing the hd_vector\n",
    "                class_prototypes[label.item()] += hd_vector\n",
    "\n",
    "            # Binarize class prototypes again after updating\n",
    "            for i in range(NUM_CLASSES):\n",
    "                class_prototypes[i] = torch.sign(class_prototypes[i])\n",
    "\n",
    "        # Compute cosine similarities with class prototypes for classification\n",
    "        similarities = torch.stack([cosine_similarity(hd_vectors, class_prototypes[i]) for i in range(NUM_CLASSES)], dim=1)\n",
    "        # print(similarities)\n",
    "        # print(similarities.shape)\n",
    "        # print(labels)\n",
    "        # print(labels.shape)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(similarities, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss and correct count\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(similarities.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate and print average loss and accuracy for this epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss}, Accuracy: {accuracy}%\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.24%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop to evaluate the model using test_loader\n",
    "hd_cnn.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    hd_vectors = hd_cnn(images)\n",
    "\n",
    "    similarities = torch.stack([cosine_similarity(hd_vectors, class_prototypes[i]) for i in range(NUM_CLASSES)], dim=1)\n",
    "    _, predicted = torch.max(similarities.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train a Vision Transformer for MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch import ViT\n",
    "\n",
    "v = ViT(\n",
    "    image_size = 28,\n",
    "    patch_size = 7,\n",
    "    num_classes = 10,\n",
    "    dim = 256,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.5,\n",
    "    emb_dropout = 0.1,\n",
    "    channels = 1\n",
    ").to(device)\n",
    "\n",
    "# Train the model\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(v.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = v(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Accuracy\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = v(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test high dimensional vector MNIST classification with varying dimensions and noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test noisy test data with varying noise levels\n",
    "noise_levels = np.arange(0, 1, 0.02)\n",
    "\n",
    "# Make varying levels of noise from 10000 upto HD_DIMENSION\n",
    "hd_dims = np.arange(10000, HD_DIMENSION, 10000)\n",
    "\n",
    "total = len(test_data.targets)\n",
    "hd_history = {}\n",
    "\n",
    "# Initialize label-wise counters\n",
    "label_counter = {i: 0 for i in range(10)}\n",
    "label_total = {i: 0 for i in range(10)}\n",
    "\n",
    "for hd_dim in hd_dims:\n",
    "    # Create projection matrix\n",
    "    proj = torch.rand((hd_dim, IMG_LEN), device=hd_device, dtype=torch.float32)\n",
    "\n",
    "    # Create hyper vectors\n",
    "    hd_vectors = generate_hd_vectors(train_data.data.view(train_data.data.shape[0], -1) / 255, proj)\n",
    "\n",
    "    # Create HD Memory\n",
    "    hd_memory = create_hd_memory(hd_vectors, train_data.targets, hd_dim)\n",
    "\n",
    "    # Convert to binary for faster computation\n",
    "    hd_vectors, hd_memory = to_binary(hd_vectors, hd_memory)\n",
    "\n",
    "    accuracies_hd = []\n",
    "    for noise_level in noise_levels:\n",
    "        noise_matrix = torch.randn((test_data.data.shape[0], IMG_LEN), device=hd_device) * noise_level\n",
    "\n",
    "        # Plot noise matrix\n",
    "        noisy_test_data = (test_data.data.view(test_data.data.shape[0], -1) / 255).to(hd_device) + noise_matrix\n",
    "\n",
    "        hd_vectors_noise = generate_hd_vectors(noisy_test_data, proj)\n",
    "        hd_vectors_noise = (hd_vectors_noise == 1).to(torch.float32)\n",
    "\n",
    "        classifications = classify_hd_vectors(hd_vectors_noise, hd_memory)\n",
    "\n",
    "        correct = torch.sum(classifications.cpu() == test_data.targets)\n",
    "\n",
    "        # Update label-wise counters\n",
    "        for true, pred in zip(test_data.targets, classifications.cpu()):\n",
    "            label_total[true.item()] += 1\n",
    "            if true == pred:\n",
    "                label_counter[true.item()] += 1\n",
    "                \n",
    "        accuracies_hd.append(correct / total * 100)\n",
    "\n",
    "    hd_history[hd_dim] = accuracies_hd\n",
    "\n",
    "# Calculate and print label-wise accuracies\n",
    "label_accuracies = {label: (label_counter[label] / label_total[label]) * 100 for label in label_counter}\n",
    "print(\"Label-wise accuracies:\", label_accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test MLP with varying noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test neural network with progressively more noise\n",
    "accuracies_net = []\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "\n",
    "    # Test noisy test data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Add noise to images\n",
    "            noise_matrix = torch.randn((images.shape[0], IMG_LEN), device=device) * noise_level\n",
    "            images = images + noise_matrix\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracies_net.append(correct / total * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ViT with varying levels of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_vit = []\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    \n",
    "        # Test noisy test data\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "    \n",
    "                # Add noise to images\n",
    "                noise_matrix = torch.randn((images.shape[0], 1, 28, 28), device=device) * noise_level\n",
    "                images = images + noise_matrix\n",
    "    \n",
    "                outputs = v(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        acc_vit.append(correct / total * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display MNIST images with noise to get an idea of how noisy the images are to the human eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random image from the test set with the various noise levels\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "index = torch.randint(0, len(test_data.targets), size=(1,)).item()\n",
    "for i, noise_level in enumerate(np.arange(0, 1, 0.1)):\n",
    "    noise_matrix = torch.randn((test_data.data.shape[0], IMG_LEN)) * noise_level\n",
    "\n",
    "    # Create noisy image\n",
    "    noisy_test_data = (test_data.data.view(test_data.data.shape[0], -1) / 255) + noise_matrix\n",
    "\n",
    "    # Create subplot and display the image\n",
    "    plt.subplot(3, 4, i + 1)  # Assuming you have 10 images (0, 0.1, ..., 0.9), adjust the dimensions as necessary\n",
    "    plt.imshow(noisy_test_data[index].view(28, 28), cmap='gray')\n",
    "    plt.title(f'Noise Level: {noise_level:.1f}')\n",
    "    plt.axis('off')  # Turn off axis numbers and ticks\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hd_dim in hd_history:\n",
    "    plt.plot(noise_levels, hd_history[hd_dim])\n",
    "plt.plot(noise_levels, accuracies_net)\n",
    "plt.plot(noise_levels, acc_vit)\n",
    "legend = []\n",
    "plt.legend([\"HD Dimension: 10000\", \"HD Dimension: 20000\", \"HD Dimension: 30000\", \"HD Dimension: 40000\", \"HD Dimension: 50000\", \"HD Dimension: 60000\", \"HD Dimension: 70000\", \"Neural Network\"])\n",
    "plt.xlabel(\"Noise Level\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Noise Level for Neural Network\")\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
